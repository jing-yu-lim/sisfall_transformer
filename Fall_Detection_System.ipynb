{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fall-Detection-System.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqKikANcIiYz/7z3DB4HSG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/Fall-Detection-System/blob/main/Fall_Detection_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIWFK9t8bVk1"
      },
      "source": [
        "Import libraries and frameworks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qhvZxm9n-jmF"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "window_size = 200\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOCs9eqca3NV"
      },
      "source": [
        "Get the sisfall and sisfall_enhanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XAle2BBAfFr"
      },
      "source": [
        "!gdown --id 1kyTRhIFhqwRkf9gERof1Xm5FVQ-klLVA\n",
        "!gdown --id 1gvOuxPc8dNgTnxuvPcVuCKifOf98-TV0\n",
        "!unzip SisFall_dataset.zip\n",
        "!unzip SisFall_enhanced.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgndfoWWKRIG"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yS1sWUdbpyd"
      },
      "source": [
        "Get all addresses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoyddPaZ-jmI"
      },
      "source": [
        "def get_file_name(path):\n",
        "  allfiles = []\n",
        "  allFolders = glob.glob(path + \"*\")\n",
        "  for files in allFolders:\n",
        "      allfiles.append(glob.glob(files+\"/*.txt\"))\n",
        "  if 'desktop.ini' in allfiles:\n",
        "        allfiles.remove('desktop.ini')\n",
        "  return np.hstack(allfiles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsyujmnJwmS_",
        "outputId": "7e28c628-75ab-49c6-8a7f-c62b62e6ea8c"
      },
      "source": [
        "get_file_name(\"SisFall_dataset/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['SisFall_dataset/SA14/F11_SA14_R04.txt',\n",
              "       'SisFall_dataset/SA14/F05_SA14_R03.txt',\n",
              "       'SisFall_dataset/SA14/D13_SA14_R05.txt', ...,\n",
              "       'SisFall_dataset/SA15/F05_SA15_R02.txt',\n",
              "       'SisFall_dataset/SA15/D16_SA15_R02.txt',\n",
              "       'SisFall_dataset/SA15/D13_SA15_R02.txt'], dtype='<U37')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCOqfWlyqoI3"
      },
      "source": [
        "read dataset from address path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkqhsxkq-jmJ"
      },
      "source": [
        "def read_data(data_path):\n",
        "    data = pd.read_csv(data_path, header=None)\n",
        "    data.columns = ['ADXL345_x', 'ADXL345_y', 'ADXL345_z', 'ITG3200_x', 'ITG3200_y', 'ITG3200_z', 'MMA8451Q_x',\n",
        "                    'MMA8451Q_y', 'MMA8451Q_z']\n",
        "    data['MMA8451Q_z'] = data['MMA8451Q_z'].map(lambda x: str(x)[:-1])\n",
        "    for name in data.columns :\n",
        "      data[name] = data[name].astype(float)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewT7PQsBqt1U"
      },
      "source": [
        "Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ6fSDVg-jmJ"
      },
      "source": [
        "def add_features(dataset,data_path):\n",
        "    new_dataset = pd.DataFrame()\n",
        "    new_dataset['acc_1'] = dataset.apply(\n",
        "        lambda row: sqrt((row.ADXL345_x ** 2 + row.ADXL345_y ** 2 + row.ADXL345_z ** 2)), axis=1)\n",
        "    new_dataset['acc_2'] = dataset.apply(\n",
        "        lambda row: sqrt((row.MMA8451Q_x ** 2 + row.MMA8451Q_y ** 2 + row.MMA8451Q_z ** 2)), axis=1)\n",
        "    new_dataset['geo'] = dataset.apply(\n",
        "        lambda row: sqrt((row.ITG3200_x ** 2 + row.ITG3200_y ** 2 + row.ITG3200_z ** 2)), axis=1)\n",
        "    new_dataset['label'] = get_label(data_path)\n",
        "    return np.round(new_dataset.to_numpy(),2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7e7B8wIq6zL"
      },
      "source": [
        "Get the Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s8X6VwxrIqS"
      },
      "source": [
        "def get_label(data_path):\n",
        "    label = data_path[21]\n",
        "    if label =='D':\n",
        "      return int(0)\n",
        "    elif label =='F':  \n",
        "      label_path = data_path.replace('dataset','enhanced')\n",
        "      labels = pd.read_csv(label_path,header=None)\n",
        "      labels[labels == 2] = 1\n",
        "      return labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxcfzuvVq-wj"
      },
      "source": [
        "Split Dataset to train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K25bf_9qJYoc"
      },
      "source": [
        "def split_address(dataset_address):\n",
        "  np.random.shuffle(dataset_address)\n",
        "  train, test = np.split(dataset_address, [int(len(dataset_address)*0.7)])\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsGm1z4krerJ"
      },
      "source": [
        "Extract features from All addresses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JxDiDpupQsq"
      },
      "source": [
        "def datasets_to_nparray(datasets_address_array):\n",
        "  result = np.empty((0, 4), int)\n",
        "  for address in datasets_address_array:\n",
        "    result = np.concatenate(\n",
        "        (result,add_features(read_data(address),address)),axis=0)\n",
        "  return result"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A375jCSrO0a"
      },
      "source": [
        "Windowing of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYq6z8xraHNQ"
      },
      "source": [
        "def windowing(dataset,window_size):\n",
        "  window = window_size * (dataset.shape[1]-1)\n",
        "  cut = dataset.shape[0] % window_size\n",
        "  feature = dataset[:-cut,0:-1]\n",
        "  label = dataset[:-cut,-1]\n",
        "  feature = feature.ravel().reshape(feature.size//window,window)\n",
        "  label = label.reshape(label.size//window_size,window_size)\n",
        "  label = label.sum(axis=1)\n",
        "  label[label > 0] = 1\n",
        "  return feature,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77t5bmxwrrVR"
      },
      "source": [
        "Save the Train and Test Dataset as Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emj874JvaBXp"
      },
      "source": [
        "def dataset_to_tensor(test,train,window_size):\n",
        "  test_feature , test_label = windowing(datasets_to_nparray(test),window_size)\n",
        "  np.savez('Sisfall_data_test', inputs=test_feature, targets=test_label)\n",
        "  train_feature , train_label = windowing(datasets_to_nparray(train),window_size)\n",
        "  np.savez('Sisfall_data_train', inputs=train_feature, targets=train_label)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}