{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fal_Detection_System_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXvzYQMBHRCMKzFx5VxqhT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/Fall-Detection-System/blob/master/Fal_Detection_System_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIWFK9t8bVk1"
      },
      "source": [
        "Import libraries and frameworks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qhvZxm9n-jmF"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "window_size = 200\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOCs9eqca3NV"
      },
      "source": [
        "Get the sisfall and sisfall_enhanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XAle2BBAfFr"
      },
      "source": [
        "!gdown --id 1kyTRhIFhqwRkf9gERof1Xm5FVQ-klLVA\n",
        "!gdown --id 1gvOuxPc8dNgTnxuvPcVuCKifOf98-TV0\n",
        "!unzip SisFall_dataset.zip\n",
        "!unzip SisFall_enhanced.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgndfoWWKRIG"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AddressProcessor:\n",
        "\n",
        "  def __init__(self, \n",
        "               data_path = \"SisFall_dataset/\")\n",
        "  self.data_path = data_path\n",
        "  \n",
        "  def get_file_name(self):\n",
        "  allfiles = []\n",
        "  allFolders = glob.glob(self.data_path + \"*\")\n",
        "  for files in allFolders:\n",
        "      allfiles.append(glob.glob(files+\"/*.txt\"))\n",
        "  if 'desktop.ini' in allfiles:\n",
        "        allfiles.remove('desktop.ini')\n",
        "  return np.hstack(allfiles)\n",
        "\n",
        "  def split_address(self):\n",
        "  dataset_address = self.get_file_name()\n",
        "  np.random.shuffle(dataset_address)\n",
        "  self.train, self.test = np.split(dataset_address, [int(len(dataset_address)*0.7)])\n",
        "\n",
        "  def main(self):\n",
        "    self.split_address()\n"
      ],
      "metadata": {
        "id": "jDXCmXMKosSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yS1sWUdbpyd"
      },
      "source": [
        "Get all addresses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoyddPaZ-jmI"
      },
      "source": [
        "def get_file_name(path):\n",
        "  allfiles = []\n",
        "  allFolders = glob.glob(path + \"*\")\n",
        "  for files in allFolders:\n",
        "      allfiles.append(glob.glob(files+\"/*.txt\"))\n",
        "  if 'desktop.ini' in allfiles:\n",
        "        allfiles.remove('desktop.ini')\n",
        "  return np.hstack(allfiles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsyujmnJwmS_",
        "outputId": "9f97d07b-b602-49f1-c1ce-069d4710cad8"
      },
      "source": [
        "get_file_name(\"SisFall_dataset/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['SisFall_dataset/SA18/F11_SA18_R03.txt',\n",
              "       'SisFall_dataset/SA18/F03_SA18_R05.txt',\n",
              "       'SisFall_dataset/SA18/F02_SA18_R04.txt', ...,\n",
              "       'SisFall_dataset/SE07/D14_SE07_R05.txt',\n",
              "       'SisFall_dataset/SE07/D16_SE07_R05.txt',\n",
              "       'SisFall_dataset/SE07/D12_SE07_R04.txt'], dtype='<U37')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCOqfWlyqoI3"
      },
      "source": [
        "read dataset from address path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetProcessor:\n",
        "  \n",
        "  def __init__(self, \n",
        "               train_dataset,\n",
        "               test_dataset,\n",
        "               window_size,\n",
        "               down_sampleing_factor)\n",
        "  self.train_dataset = train_dataset\n",
        "  self.test_dataset = test_dataset\n",
        "  self.window_size = window_size\n",
        "  self.down_sampleing_factor = down_sampleing_factor\n",
        "  \n",
        "  def read_data(self, data_path):\n",
        "    data = pd.read_csv(data_path, header=None)\n",
        "    data.columns = ['ADXL345_x', 'ADXL345_y', 'ADXL345_z', 'ITG3200_x', 'ITG3200_y', 'ITG3200_z', 'MMA8451Q_x',\n",
        "                    'MMA8451Q_y', 'MMA8451Q_z']\n",
        "    data['MMA8451Q_z'] = data['MMA8451Q_z'].map(lambda x: str(x)[:-1])\n",
        "    for name in data.columns :\n",
        "      data[name] = data[name].astype(float)\n",
        "    return data\n",
        "\n",
        "  def add_features(self, data_path):\n",
        "    dataset = self.read_data(data_path)\n",
        "    new_dataset = pd.DataFrame()\n",
        "    new_dataset['acc_1'] = dataset.apply(\n",
        "        lambda row: sqrt((row.ADXL345_x ** 2 + row.ADXL345_y ** 2 + row.ADXL345_z ** 2)), axis=1)\n",
        "    new_dataset['acc_2'] = dataset.apply(\n",
        "        lambda row: sqrt((row.MMA8451Q_x ** 2 + row.MMA8451Q_y ** 2 + row.MMA8451Q_z ** 2)), axis=1)\n",
        "    new_dataset['geo'] = dataset.apply(\n",
        "        lambda row: sqrt((row.ITG3200_x ** 2 + row.ITG3200_y ** 2 + row.ITG3200_z ** 2)), axis=1)\n",
        "    new_dataset['label'] = get_label(data_path)\n",
        "    return np.round(new_dataset.to_numpy(),2)\n",
        "\n",
        "  def get_label(self, data_path):\n",
        "    label = data_path[21]\n",
        "    if label =='D':\n",
        "      return int(0)\n",
        "    elif label =='F':  \n",
        "      label_path = data_path.replace('dataset','enhanced')\n",
        "      labels = pd.read_csv(label_path,header=None)\n",
        "      labels[labels == 2] = 1\n",
        "      return labels\n",
        "\n",
        "  def datasets_to_nparray(self):\n",
        "    result = np.empty((0, 4), int)\n",
        "    for address in datasets_address_array:\n",
        "      result = np.concatenate(\n",
        "          (result,self.add_features(read_data(address),address)),axis=0)\n",
        "    return result\n",
        "  \n",
        "  def windowing(self, dataset):\n",
        "    window = self.window_size * (dataset.shape[1]-1)\n",
        "    cut = dataset.shape[0] % self.window_size\n",
        "    feature = dataset[:-cut,0:-1]\n",
        "    label = dataset[:-cut,-1]\n",
        "    feature = feature.ravel().reshape(feature.size//window,window)\n",
        "    label = label.reshape(label.size//self.window_size,self.window_size)\n",
        "    label = label.sum(axis=1)\n",
        "    label[label > 0] = 1\n",
        "    return feature,label\n",
        "\n",
        "  def dataset_to_tensor(self):\n",
        "    test_feature, test_label = self.windowing(self.datasets_to_nparray(self.test_dataset),self.window_size)\n",
        "    np.savez('Sisfall_data_test', inputs=test_feature, targets=test_label)\n",
        "    train_feature, train_label = self.windowing(self.datasets_to_nparray(self.test_dataset),self.window_size)\n",
        "    np.savez('Sisfall_data_train', inputs=train_feature, targets=train_label)\n",
        "\n",
        "  def dataset_loader(self):\n",
        "    npz = np.load(\"Sisfall_data_train.npz\")\n",
        "    self.train_inputs = preprocessing.scale(npz[\"inputs\"].astype(np.float))\n",
        "    self.train_targets = npz[\"targets\"].astype(np.int)\n",
        "    \n",
        "    npz = np.load(\"Sisfall_data_test.npz\")\n",
        "    self.test_inputs = preprocessing.scale(npz[\"inputs\"].astype(np.float))\n",
        "    self.test_targets = npz[\"targets\"].astype(np.int)\n",
        "\n",
        "  def downsampling(self):\n",
        "      positive = self.train_inputs[self.train_inputs['targets']==1]\n",
        "      negative = self.train_inputs[self.train_inputs['targets']==0].sample(n=int(len(positive)*self.down_sampleing_factor))\n",
        "      return pd.concat([positive, negative], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  def main(self):\n",
        "    self.dataset_to_tensor()\n",
        "    self.dataset_loader()\n",
        "    self.downsampling()\n"
      ],
      "metadata": {
        "id": "Rh4rp7_Z_i0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXsG6DAmfm7m"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oiw8XrQ3O59"
      },
      "source": [
        "Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsuvZYw8g1wu"
      },
      "source": [
        "Neural Network Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Models:\n",
        "\n",
        "  def __init__(self, \n",
        "               X_train,\n",
        "               y_train,\n",
        "               X_test,\n",
        "               y_test,\n",
        "               batch_size = 128,\n",
        "               n_epochs = 100,\n",
        "               filters = 250,               \n",
        "               kernel_size = 3,\n",
        "               units = 250,\n",
        "               optimizer = tf.optimizers.SGD,\n",
        "               drop_rate = 0.4,\n",
        "               learning_rate = 0.02,\n",
        "               validation_split = 0.10\n",
        "               ):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.units = units\n",
        "        self.optimizer = optimizer\n",
        "        self.drop_rate = drop_rate\n",
        "        self.learning_rate = learning_rate\n",
        "        self.validation_split = validation_split\n",
        "\n",
        "  def define_mlp(self):\n",
        "\n",
        "    self.mlp_model = tf.keras.Sequential([\n",
        "                                tf.keras.layers.Dense(self.input_size,activation=\"relu\"),\n",
        "                                tf.keras.layers.Dense(self.hidden_layer_size, activation=\"relu\"),\n",
        "                                tf.keras.layers.Dense(self.hidden_layer_size,activation=\"relu\"),\n",
        "                                tf.keras.layers.Dense(self.output_size, activation='sigmoid')\n",
        "                                ])\n",
        "\n",
        "    self.mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  def train_mlp(self):\n",
        "    self.mlp_history = self.mlp_model.fit(\n",
        "        self.X_train,\n",
        "        self.y_train,\n",
        "        batch_size = self.batch_size,\n",
        "        epochs = self.n_epochs,\n",
        "        shuffle = True,\n",
        "        verbose = 1\n",
        "          )\n",
        "\n",
        "  def plot_cnn_training_history(self):\n",
        "    return plot_history(self.mlp_history)\n",
        "\n",
        "  def evaluate_mlp(self):\n",
        "    self.mlp_prediction = self.mlp_model.predict(self.X_test, verbose = 1, batch_size = self.batch_size)\n",
        "    print(classification_report(self.y_test, self.mlp_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.mlp_prediction))\n",
        "    \n",
        "\n",
        "  def define_lstm(self):\n",
        "    return\n",
        "  \n",
        "  def train_lstm(self):\n",
        "    return\n",
        "\n",
        "  def evaluate_lstm(self):\n",
        "    return\n",
        "    \n",
        "  def define_svm(self):\n",
        "    self.svm_model = LinearSVC(C = 0.0001)\n",
        "    self.svm_model.fit(self.X_train, self.y_train)\n",
        "\n",
        "  def evaluate_svm(self):\n",
        "    self.svm_prediction = self.svm_model.predict(self.X_test)\n",
        "    print(classification_report(self.y_test, self.svm_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.svm_prediction))\n",
        "  \n",
        "    def define_LGR(self):\n",
        "    self.LGR_model = LogisticRegression()\n",
        "    self.LGR_model.fit(self.X_train, self.y_train)\n",
        "    \n",
        "  def evaluate_LGR(self):\n",
        "    self.LGR_prediction = self.LGR_model.predict(self.X_test)\n",
        "    print(classification_report(self.y_test, self.LGR_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.LGR_prediction))\n",
        "  \n",
        "  def define_knn(self):\n",
        "    self.knn_model = KNeighborsClassifier(n_neighbors=4)\n",
        "    self.knn_model.fit(self.X_train, self.y_train)\n",
        "    \n",
        "  def evaluate_knn(self):\n",
        "    self.knn_prediction = self.knn_model.predict(self.X_test)\n",
        "    print(classification_report(self.y_test, self.knn_prediction))\n",
        "    print(confusion_matrix(self.y_test, self.knn_prediction))\n",
        "\n",
        "  def define_ensemble_concept(self):\n",
        "\n",
        "  def evaluate_ensemble_concept(self):"
      ],
      "metadata": {
        "id": "lXXuUHUODbJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CzHQADbnzVt"
      },
      "source": [
        "Prediction based on Ensemble Concept"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEiwDqETny3u",
        "outputId": "21d8f5f8-d722-41cb-db38-f6c558915c75"
      },
      "source": [
        "def ensmble_concept(Knn_prediction,model_prediction):\n",
        "  return np.logical_or(Knn_prediction , model_prediction.T.ravel().round())\n",
        "\n",
        "result = ensmble_concept(y_pred,predictions)\n",
        "print(classification_report(y_test, result))\n",
        "print(confusion_matrix(y_test, result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     22857\n",
            "           1       0.65      0.81      0.72      1072\n",
            "\n",
            "    accuracy                           0.97     23929\n",
            "   macro avg       0.82      0.90      0.85     23929\n",
            "weighted avg       0.98      0.97      0.97     23929\n",
            "\n",
            "[[22379   478]\n",
            " [  201   871]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT1qAAPVHRDD"
      },
      "source": [
        "Models' Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "E4-Ab6KrGkNv",
        "outputId": "37cb1cb3-3976-49d6-d813-eb690ea4ed86"
      },
      "source": [
        "conclusion = pd.DataFrame([['Neural Network',precision_1,recall_1,f1Score_1],\n",
        "              ['Logistic Regression',0.53,0.17,0.26],\n",
        "              ['SVM',0.38,0.01,0.03],\n",
        "              ['KNN',0.94,0.56,0.70],\n",
        "              ['Neural Network after Balancing',precision_2,recall_2,f1Score_2],\n",
        "              ['Logistic Regression after Balancing',0.08,0.93,0.15],\n",
        "              ['SVM after Balancing',0.06,0.97,0.11],\n",
        "              ['KNN after Balancing',0.73,0.73,0.73],\n",
        "              ['Ensemble concept after Balancing',0.65,0.81,0.72]],\n",
        "              columns=[\"Algorithm\",\"Precision\",\"Recall\",\"F1score\"])\n",
        "conclusion = conclusion.set_index('Algorithm')\n",
        "conclusion.style.background_gradient(cmap=\"YlOrRd\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row0_col0,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row6_col1,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row7_col2{\n",
              "            background-color:  #800026;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row0_col1,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row2_col0{\n",
              "            background-color:  #febb56;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row0_col2{\n",
              "            background-color:  #f03523;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row1_col0{\n",
              "            background-color:  #fd8a3b;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row1_col1{\n",
              "            background-color:  #ffe793;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row1_col2{\n",
              "            background-color:  #fec05b;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row2_col1,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row2_col2,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row6_col0{\n",
              "            background-color:  #ffffcc;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row3_col0{\n",
              "            background-color:  #990026;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row3_col1{\n",
              "            background-color:  #fc6832;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row3_col2,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row4_col2,#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row5_col1{\n",
              "            background-color:  #930026;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row4_col0{\n",
              "            background-color:  #b90026;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row4_col1{\n",
              "            background-color:  #fc5d2e;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row5_col0{\n",
              "            background-color:  #fffcc5;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row5_col2{\n",
              "            background-color:  #ffe691;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row6_col2{\n",
              "            background-color:  #ffefa4;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row7_col0{\n",
              "            background-color:  #e9261f;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row7_col1{\n",
              "            background-color:  #e2191c;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row8_col0{\n",
              "            background-color:  #fa4a29;\n",
              "            color:  #000000;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row8_col1{\n",
              "            background-color:  #c90823;\n",
              "            color:  #f1f1f1;\n",
              "        }#T_611e1a9c_5135_11ec_be3e_0242ac1c0002row8_col2{\n",
              "            background-color:  #860026;\n",
              "            color:  #f1f1f1;\n",
              "        }</style><table id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002\" class=\"dataframe\"><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Precision</th>        <th class=\"col_heading level0 col1\" >Recall</th>        <th class=\"col_heading level0 col2\" >F1score</th>    </tr>    <tr>        <th class=\"index_name level0\" >Algorithm</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >Neural Network</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row0_col0\" class=\"data row0 col0\" >0.990000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.340000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.510000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >Logistic Regression</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row1_col0\" class=\"data row1 col0\" >0.530000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.170000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0.260000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >SVM</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.380000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.010000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0.030000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >KNN</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row3_col0\" class=\"data row3 col0\" >0.940000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.560000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.700000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >Neural Network after Balancing</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row4_col0\" class=\"data row4 col0\" >0.880000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.580000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row4_col2\" class=\"data row4 col2\" >0.700000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >Logistic Regression after Balancing</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row5_col0\" class=\"data row5 col0\" >0.080000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.930000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row5_col2\" class=\"data row5 col2\" >0.150000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >SVM after Balancing</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row6_col0\" class=\"data row6 col0\" >0.060000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.970000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row6_col2\" class=\"data row6 col2\" >0.110000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >KNN after Balancing</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row7_col0\" class=\"data row7 col0\" >0.730000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0.730000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row7_col2\" class=\"data row7 col2\" >0.730000</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >Ensemble concept after Balancing</th>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row8_col0\" class=\"data row8 col0\" >0.650000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row8_col1\" class=\"data row8 col1\" >0.810000</td>\n",
              "                        <td id=\"T_611e1a9c_5135_11ec_be3e_0242ac1c0002row8_col2\" class=\"data row8 col2\" >0.720000</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fa5792cc150>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAV6ArSEQ0xd"
      },
      "source": [
        "As you see After Blancing the dataset Ensemble concept and KNN model do the best !"
      ]
    }
  ]
}